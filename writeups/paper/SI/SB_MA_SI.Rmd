---
title: 'Syntactic Bootstrapping MA'
author: "Anjie Cao and Molly Lewis"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: no
subtitle: Supplementary Information
---

******
******

```{r setup, include = F}
# load packages
library(tidyverse)
library(knitr)
library(here)
library(metafor)
library(ggimage)
library(imager)
library(stringr)
library(glue)
library(heatmaply)
source(here("writeups/paper/scripts/model_print.R"))
source(here("writeups/paper/scripts/forest_plot_helper.R"))
source(here("writeups/paper/scripts/funnel_plot_helper.R"))
source(here("writeups/paper/scripts/predictor_plot_helper.R"))

opts_chunk$set(echo = F, message = F, warning = F, 
               error = F, cache = F, tidy = F, fig.height = 4.5)

theme_set(theme_classic())
options(shiny.sanitize.errors = FALSE)
```  

<a href="https://github.com/anjiecao/SyntacticBootstrapping" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm</style>

This document was created from an R markdown file. The repository for the project can be found here: https://github.com/anjiecao/SyntacticBootstrapping. The data reported in the paper can be explored interactively at the [Metalab website](http://metalab.stanford.edu/).

```{r}
DATA_PATH <- here("data/processed/syntactic_bootstrapping_tidy_data.csv") 
RAW_DATA_PATH <- here("data/raw/syntactic_bootstrapping_raw_data.csv")

ma_data <- read_csv(DATA_PATH)
ma_raw_data <- read_csv(RAW_DATA_PATH)
```


# Heat Map {.tabset}

The heatmaps below showed the overlappings between moderators. Each cell corresponds to the coocurrences between two moderator levels. Brighter colors indicate higher frequency of co-occurence, and darker colors indicate lower frequency. You can hover your mouse on the heatmap to see the corresponding value and combination on each cell. 


## Ordered by Row Average 
```{r}
ALL_CATEGORICAL_VARS <- c("presentation_type_collapsed",
                      #"agent_argument_type", "patient_argument_type", 
                     "stimuli_modality", "stimuli_actor", "character_identification",   "practice_phase", "test_mass_or_distributed", "transitive_event_type", "intransitive_event_type")


get_cross_counts <- function(args, df){
  var1 = args[[1]]
  var2 = args[[2]]
  
  if (var1 != var2){
  
  df %>%
    select_(var1, var2) %>%
    rename(v1 = var1, 
          v2 = var2) %>%
    count(v1, v2) %>%
    mutate(v1_long = glue("{var1}/{v1}"),
           v2_long = glue("{var2}/{v2}"))  %>%
    select(v1_long, v2_long, n) 

  }
}

all_pair_counts <- list(ALL_CATEGORICAL_VARS,
                        ALL_CATEGORICAL_VARS) %>%
  cross() %>%
  map_df(get_cross_counts, ma_data) %>%
  complete(v1_long, v2_long, fill = list(n = 0)) %>%
  filter(v1_long != v2_long)


  all_counts_wide <- all_pair_counts %>%
    pivot_wider(names_from = v2_long, values_from = n) 
  

  all_counts_wide_matrix <- all_counts_wide %>%
    select(-v1_long) %>%
    as.matrix()
  
  row.names(all_counts_wide_matrix) <-  as.character(all_counts_wide$v1_long)
  heatmaply(all_counts_wide_matrix,
            fontsize_row = 8,
            fontsize_col = 8)
```

## Ordered alphabetically          
```{r}
heatmaply(all_counts_wide_matrix,
            fontsize_row = 8,
            fontsize_col = 8,
           Rowv = NA)
```


# Additional Moderators (follow after Arunachalam (2017))
```{r include=FALSE}
ADDITIONAL_MODERATORS <- c("stimuli_modality", "stimuli_actor",  "transitive_event_type", "intransitive_event_type")
INTRANSITIVE <- c("patient_argument_type")
additional_main <- generate_moderator_df(ADDITIONAL_MODERATORS, ma_data)
intransitive <- generate_moderator_df(INTRANSITIVE, filter(ma_data, sentence_structure == "transitive"))
additional_main <- bind_rows(additional_main, intransitive) %>% 
  select(this_moderator, n, 
         estimate_print_full, z_print, p_print, 
         mod_estimate_print_full, mod_CI_print, mod_z_print, mod_p_print) %>% 
  mutate(
    intercept = estimate_print_full, 
    moderator = mod_estimate_print_full,
    intercept_z_val = gsub("= ","", z_print), 
    intercept_p_val = gsub("= ", "", p_print),
    mod_z_val = gsub("= ", "", mod_z_print),
    mod_p_val = gsub("= ", "", mod_p_print)
  )

```

## Patient argument type for transitive sentence 

In the main analysis we presented results of the model for the relationship between effect size and the agent argument type. We found that having nouns or pronouns int he agent argument does not significantly predict the effect size. Here, we presented a similar anlaysis on the influence of the patient argument type. Because by definition English intransitive sentences do not have patient argument, we focus on the subset of studies that used the transitive sentences ($N$ = `r filter(additional_main, this_moderator == "patient_argument_type")$n`)

```{r}

pretty_moderator_name <- function(s){
  new_s <- str_to_title(gsub("_", " ",s))
  return(new_s)
}

convert_pretty_print_table <- function(full_df, current_moderator){
  
  estimates <- full_df %>% 
    filter(this_moderator == current_moderator) %>% 
    pivot_longer(cols = c(intercept, moderator), names_to = "Parameter", values_to = "Estimate") %>% 
    select(Parameter, Estimate)
  
  z_val <- full_df %>% 
    filter(this_moderator == current_moderator) %>% 
    pivot_longer(cols = c(intercept_z_val, mod_z_val), names_to = "Parameter", values_to = "z value") %>% 
    select("z value")
  
  p_val <- full_df %>% 
    filter(this_moderator == current_moderator) %>% 
    pivot_longer(cols = c(intercept_p_val, mod_p_val), names_to = "Parameter", values_to = "p value") %>% 
    select("p value")
  
  all_df <- bind_cols(estimates, z_val, p_val) %>% 
    mutate(
      Parameter = case_when(
        Parameter == "moderator" ~ pretty_moderator_name(current_moderator),
        Parameter == "intercept" ~ "Intercept"
      )
    )
  
  return(all_df)
  
}


patient_argument_type_table <- convert_pretty_print_table(additional_main, "patient_argument_type")

patient_argument_type_table %>% 
  kable() 
```



## Stimuli Modality (Video or Animation)

We found that the presentation modality of the stimuli was not a significant perdictor of the effect size. In other words, studies that presented young children with animation clips had similar effect sizes as studies using video clips. The model statistics is shown below. Note that the stimuli modality and the stimuli actor levels had a lot of overlapping studies, so researchers should interpret this result with cautions. 


```{r}
stimuli_argument_type_table <- convert_pretty_print_table(additional_main, "stimuli_modality")
stimuli_argument_type_table %>% 
  kable()
```


## Stimuli actors (Person or Non-person)
Similarlty, we did not find an effect of stimuli actors. Studies with human actors as protagonists in the events had similar effect sizes as studies using puppets, human actors in animal suits, or using animated geometrical shapes. 

```{r}
stimuli_actor_type_table <- convert_pretty_print_table(additional_main, "stimuli_actor")
stimuli_actor_type_table %>% 
  kable()
```

## Type of event {.tabset}
Studies differed in the type of transitive events and intransitive events they presented. Previous studies have shown that young children's looking behaviors in Inter-modal Preferential Looking Paradigm were very sensitive to the subtle perceptual differences in the visual stimuli (Delle Luche, Durrant, Poltrock, & Floccia, 2015; Fernald, Zangl, Portillo, & Marchman, 2008).Therefore, we coded the types of events presented in the visual stimuli. There were two types of transitive events: direct causal action and indirect causal action. The former involved the agent directly acting on the patient and causing the patient to move. The latter involved a mean-end sequence leading to the caused action of the patient. For example, the agent may pulled a band on the patient's waist and caused it to move. There were also two types of intransitive events used in the literature. One involved single actor performing an action, such as jumping up and down. The other involved two actors presented without any causal action. 

Our model suggested that neither of the variables was predictive of the effect sizes. 



### Transitive Event: Direct causal action or Indirect causal action
```{r}
transitive_event_type_table <- convert_pretty_print_table(additional_main, "transitive_event_type")
transitive_event_type_table %>% 
  kable()
```
### Intransitive Event: Single-actor or parallel actions
```{r}
intransitive_event_type_table <- convert_pretty_print_table(additional_main, "intransitive_event_type")
intransitive_event_type_table %>% 
  kable()
```


 





# Variability in visual stimuli as a function of age

There was some evidence for researchers adapting the level of visual complexity in the visual stimuli according to children's age. We collected the available visual stimuli from the papers and the supporting materials. Schematic illustraions of the visual stimuli were used when the actual screenshots were not provided. Screenshots of the text descriptions of the events were used when the visual stimuli were unavailable. Note that because some papers' publishers converted to the visual stimuli to black-and-white, we decided to grayscale all visual stimuli for easier visual comparison.  

It is easy to see that in the plot studies for particular young children used significantly simpler visual stimuli. This adaptation might be partly responsible for the lack of age effect observed in our samples.  


```{r}

ma_data <- read_csv(DATA_PATH) %>% 
  mutate(row_id = 1:n()) %>%
  rowwise() %>%
  mutate(stim_path = paste(unique_id, expt_num, sentence_structure,sep = "_"),
         stim_path = paste0(here("resources/stimuli_forplot/"), stim_path, ".png"),
         stim_path = str_replace(stim_path, "yuan2012_3_", "yuan2012_3simple_"))


age_model <- rma.mv(d_calc ~ mean_age, V = d_var_calc,
                      random = ~ 1 | short_cite/same_infant/row_id,
                      method = "REML",
                      data = ma_data )


```

```{r, fig.width = 10, fig.height = 8}
ma_data_with_predictions <- predict(age_model) %>%
  as.data.frame() %>%
  bind_cols(ma_data) %>% 
  mutate(
    mean_age_months = mean_age / 30.44
  )

ggplot(ma_data_with_predictions, aes(x = mean_age_months, y = d_calc)) +
  geom_image(aes(image = stim_path)) +
  geom_smooth(method = "lm") +
  #geom_smooth(method = "lm", data = ma_data_with_predictions, aes(x = mean_age, y = pred)) +
  ylab("Effect Size (d)") +
  xlab("Mean age (months)")
```



**References**

Bedny M., Koster-Hale J., Elli G., Yazzolino L., Saxe R. (2019) There’s more to “sparkle” than meets the eye: Knowledge of vision and light verbs among congenitally blind and sighted individuals.  _Cognition_ 189:105–115.

Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2016). Enriching word vectors with subword information. https://arxiv.org/abs/1607.04606

de Vries, A.  &  Ripley, B. D. (2016). ggdendro: Create Dendrograms and Tree Diagrams Using 'ggplot2'. R package version 0.1-20. https://CRAN.R-project.org/package=ggdendro

Delle Luche, C., Durrant, S., Poltrock, S., & Floccia, C. (2015). A methodological investigation of the Intermodal Preferential Looking paradigm: Methods of analyses, picture selection and data rejection criteria. Infant Behavior and Development, 40, 151-172

Fernald, A., Zangl, R., Portillo, A. L., & Marchman, V. A. (2008). Looking while listening: Using eye movements to monitor spoken language. Developmental psycholinguistics: On-line methods in children’s language processing, 44, 97.


Galili, T. (2015). dendextend: an R package for visualizing, adjusting, and comparing trees of hierarchical clustering. Bioinformatics. DOI: 10.1093/bioinformatics/btv428

Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. _arXiv preprint arXiv:1301.3781_.
