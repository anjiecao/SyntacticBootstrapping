---
title: 'Syntactic Bootstrapping MA'
author: "Anjie Cao and Molly Lewis"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: paper
    toc: yes
    toc_float: no
subtitle: Supplementary Information
---

******
******

```{r setup, include = F}
# load packages
library(tidyverse)
library(pwr)
library(knitr)
library(here)
library(kableExtra)
library(metafor)
library(ggimage)
library(imager)
library(stringr)
library(glue)
library(heatmaply)
library(PublicationBias)
source(here("writeups/paper/scripts/model_print.R"))
source(here("writeups/paper/scripts/forest_plot_helper.R"))
source(here("writeups/paper/scripts/funnel_plot_helper.R"))
source(here("writeups/paper/scripts/predictor_plot_helper.R"))
source(here("writeups/paper/scripts/SI_table_helper.R"))
alpha = 0.5


opts_chunk$set(echo = F, message = F, warning = F, 
               error = F, cache = F, tidy = F, fig.height = 4.5)

theme_set(theme_classic())
options(shiny.sanitize.errors = FALSE)
```  

<a href="https://github.com/anjiecao/SyntacticBootstrappingMA" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm</style>

This document was created from an R markdown file. The repository for the project can be found [here](https://github.com/anjiecao/SyntacticBootstrapping). The data reported in the paper can be explored interactively at the [Metalab website](http://metalab.stanford.edu/).

```{r }
DATA_PATH <- here("data/processed/syntactic_bootstrapping_tidy_data.csv") 
RAW_DATA_PATH <- here("data/raw/syntactic_bootstrapping_raw_data.csv")
ALTERNATIVE_ES_PATH <- here("writeups/paper/SI/alt_ES.csv")

ma_data <- read_csv(DATA_PATH) 
ma_raw_data <- read_csv(RAW_DATA_PATH)

alt_raw_data <- read_csv(ALTERNATIVE_ES_PATH)
alt_data <- alt_raw_data %>% 
  filter(alternative_calc == "between") %>% 
  mutate(
    pooled_SD = sqrt(((n_1 - 1) * sd_1 ^ 2 + (n_2 - 1) * sd_2 ^ 2) / (n_1 + n_2 - 2)), 
    d_calc = (x_1 - x_2) / pooled_SD, 
    d_var_calc = ((n_1 + n_2) / (n_1 * n_2)) + (d_calc ^ 2 / (2 * (n_1 + n_2)))
    )
```


# Comparison between between subjects effect sizes and within subjects effect size

The forest plot below compares the two ways of calculating effect sizes, using a subset of experimental conditions. The subset was chosen because in the original paper the main analyses presented for these conditions were between-group calculation. In other words, the original analyses compared the porportion of looking time at the causative events between transitive conditions and intransitive conditions. Effect sizes calculated using these methods were denoted by the red dots. We also presented the effect sizes calculated using the against-chance method on the same subset of the experimental conditions. These effect sizes are denoted with black dots. The against-chance method is a more conservative way of estimating the effect size. As the forest plot shows, the meta-analytic effect size using the between-group calculation is larger than the meta-analytic effect size using the against-chance method. 


```{r}
# select the same subset of ES for comparison
alt_id <- alt_data %>% 
  filter(alternative_calc == "between") %>% 
  select(unique_id) %>% 
  pull

ma_subset <- ma_data %>% 
  filter(unique_id %in% alt_id) %>% 
  filter(sentence_structure == "transitive") %>% 
  select(unique_id, short_cite, 
         same_infant, plot_label, n_1, d_calc, d_var_calc, row_id) %>% 
  mutate(calc_type = "within")

alt_subset <- alt_data %>% 
  rowid_to_column() %>% 
  rename(row_id = rowid) %>% 
  select(unique_id, short_cite, 
         same_infant, plot_label,n_1, d_calc, d_var_calc, row_id) %>% 
  mutate(calc_type = "between")
```


```{r}
convert_to_forest_data <- function(raw_data){
  # model for cumulative effect size 
  model <- rma.mv(d_calc, 
                  V = d_var_calc,
                  random = ~ 1 | short_cite/same_infant/row_id,
                  method = "REML",
                  data = raw_data)

  this_moderator_estimate <- model$b[1]
  this_moderator_SE <- model$se[1]
  this_moderator_estimate.cil <- model$ci.lb[1]
  this_moderator_estimate.cih <- model$ci.ub[1]
  this_moderator_z <- model$zval[1]
  this_moderator_p <- model$pval[1]

  # function to abbreviate label 
abbreviate_label <- function(original_label){
  label_vec <- unlist(strsplit(original_label, ","))
  # get the first label 
  first_author_name <- label_vec[[1]]
  year <- gsub("(-).*","",tail(label_vec, n=1))
  number_label <- gsub(".*-","",tail(label_vec, n=1))
  abbreviated_label <- paste0(first_author_name, " et al.,", year, "-", number_label)
}

individual_data <- raw_data %>% 
    select(short_cite, unique_id,d_calc,d_var_calc, n_1, plot_label,calc_type, row_id) %>% 
    rowwise() %>% 
    mutate(cil = d_calc - qnorm(alpha / 2, lower.tail = FALSE) * sqrt(d_var_calc),
           cil = case_when(
             (cil < -8) ~ -8, # truncate error bar for visibility reason 
             TRUE ~ cil
           ),
           ciu = d_calc +
             qnorm(alpha / 2, lower.tail = FALSE) * sqrt(d_var_calc), 
           ciu = case_when(
             (ciu > 5 ) ~ 5, # truncate error bar for visibility reason 
             TRUE ~ ciu
           ),
           es_type = "individual",
           meta = "no", 
           label_color = "black",
           print_full = paste(round(d_calc,2), " [",round(cil,2),", ",round(ciu,2), "]", sep = ""),
           plot_label = case_when(
             str_count(plot_label,",") >= 4 ~ abbreviate_label(plot_label),
             TRUE ~ plot_label
           )
)

cumulative_data <- tibble_row(
  short_cite = "Meta-Analytic Effect Size",
           plot_label = "Meta-Analytic Effect Size",
           d_calc = this_moderator_estimate, 
           d_var_calc = NA, 
           n_1 = 99, 
           cil = this_moderator_estimate.cil, 
           ciu = this_moderator_estimate.cih, 
           es_type = "cumulative",
           print_full = paste(round(d_calc,2), " [",round(cil,2),", ",round(ciu,2), "]", sep = ""), 
  meta = "yes", 
           label_color = "red", 
  row_id = 0, 
  calc_type = unique(individual_data$calc_type)
)

forest_data <- bind_rows(individual_data, cumulative_data)
  
  return (forest_data)
}


```

```{r}
within_forest_data <- convert_to_forest_data(ma_subset)
between_forest_data <- convert_to_forest_data(alt_subset)
double_forest_data <- bind_rows(within_forest_data, between_forest_data)
```

```{r}
double_forest_data_withorder <- double_forest_data %>% 
    rowid_to_column() %>% 
    mutate(
      rowid = if_else(es_type == "cumulative", 99, as.double(rowid)), #to always put the MA ES at bottom
      point_shape = if_else(es_type == "cumulative", 18, 16), 
      point_color = case_when(
        es_type == "cumulative" && calc_type == "within" ~ "black",
        es_type == "cumulative" && calc_type == "between" ~ "red",
        calc_type == "between" ~ "red", 
        calc_type == "within" ~ "black"
      ), 
      label_color = case_when(
        es_type == "cumulative" ~  "red", 
        es_type == "individual" ~ "black"
      )
    ) %>% 
    group_by(calc_type) %>% arrange(-rowid, .by_group = FALSE)

 mm_to_point = 18/6.5
  label_size = 5
  x_axis_title <- expression(paste("Cohen\'s ", italic('d')))
    

double_forest_data_withorder %>%  # First sort by val. This sort the dataframe but NOT the factor levels
    ggplot(aes(x = fct_reorder(plot_label, -rowid),
               y = d_calc,
               ymin = cil, 
               ymax = ciu, 
               group = calc_type, 
               color = calc_type
               )) + 
    geom_hline(aes(yintercept = 0),  color = "gray44",linetype = 2, size =.3) + 
    geom_hline(aes(yintercept = filter(double_forest_data_withorder, es_type == "cumulative", calc_type == "within")$d_calc), 
              color = "black", linetype = 2, size = .3) + 
   geom_hline(aes(yintercept = filter(double_forest_data_withorder, es_type == "cumulative", calc_type == "between")$d_calc), 
              color = "red", linetype = 2, size = .3) +
    geom_pointrange(size = .5, 
                    shape = double_forest_data_withorder$point_shape,
                    aes(color = double_forest_data_withorder$calc_type),
                    position = position_dodge(1), 
                    alpha = 1, 
                    ) + 
    scale_color_manual(breaks = c("between", "within"),
                       values = c("red", "black"))+ 
    geom_text(aes(label = print_full, 
                  x = plot_label, y = 4.2,
                   color = double_forest_data_withorder$calc_type), 
              position = position_dodge(1),
              size = label_size / mm_to_point, 
             ) +
   scale_color_manual(breaks = c("between", "within"),
                       values = c("red", "black"))+ 
    coord_cartesian(clip = 'on') + 
    coord_flip() + 
    ylim(-1.8, 5)+ 
    ylab(x_axis_title) +
    labs(color  = "Effect Size Type",shape = "Effect Size Type") + # merge two legends 
    theme(text = element_text(size=label_size),
          legend.position="bottom",
          legend.text=element_text(size=label_size*1.5),
          plot.margin = unit(c(1,1,1,1), "lines"),
          legend.title = element_blank(),
          panel.background = element_blank(),
          #panel.background = element_rect(fill = "white", colour = "grey50"),
          axis.title.y = element_blank(),
          axis.title.x = element_text(size=label_size*1.5),
          axis.text.y = element_text(size = label_size), 
          axis.text.x = element_text(size = label_size * 2)) 
```



```{r}
#generate_double_forest_plot(double_forest_data)
```




```{r}

```




# Details of calculating effect size


To standardize the effect size calculation, we converted some reported raw results to the proportion of correct responses. For looking time studies, when the paper only reported the raw looking time in seconds, we calculated the proportion of correct response by dividing the mean looking time toward the matching scene by the sum of looking time toward the matching scenes and non-matching scenes (i.e., excluding the look away time from the denominator). The raw standard deviations were also converted to the corresponding values by being divided by the sum.

Below is a step-by-step example calculation using data in Yuan & Fisher (2009) Experiment. The table presents raw data from Yuan & Fisher (2009, pg 622) Table 1. The values are Mean looking time in seconds, and in parentheses are SE.


```{r}
tibble(
  "Dialogue Type" = c("Transitive", "Intransitive"),
  "Sample Size" = c("8", "8"),
  "Two-participant Event" = c("4.82 (0.43)", "3.33 (0.24)"), 
  "One-participant Event" = c("2.87 (0.51)", "4.12 (0.40)")) %>% kable() %>% 
  kable_styling(font_size = 12)
```

When the paper only provides raw looking time data, we converted the data into proportion of correct looking time and the variances following the formulae below. For children hearing transitive sentences, the correct scene was the Two-participant Event. For children hearing intransitive sentences, the correct scene was the One-participant Event. Standard Deviations were calculated by scaling the raw SE first, and then multiplied by the square roots of the number of participants."

\begin{aligned}
Mean_{Proportion} &= \frac{Time_{correct}}{Time_{correct} + Time_{incorrect}} \\
SD_{Proportion} &= \frac{SE_{Raw}}{Time_{correct} + Time_{incorrect}} * \sqrt[2]{N}\\
\\
\\
\end{aligned}

\begin{aligned}
Mean_{transitive} &= \frac{Time_{correct}}{Time_{correct} + Time_{incorrect}} \\
  &= \frac{4.82}{4.82 + 2.87} \\
  &= 0.627 \\

SD_{transitive} &= \frac{SE_{Raw}}{Time_{correct} + Time_{incorrect}} * \sqrt[2]{N} \\
  &= \frac{0.43}{4.82 + 2.87} *  \sqrt[2]{8} \\
  &= 0.158 \\

\\
\\
\end{aligned}

\begin{aligned}
Mean_{intransitive} &= \frac{Time_{correct}}{Time_{correct} + Time_{incorrect}} \\
  &= \frac{4.12}{3.33 + 4.12} \\
  &= 0.553 \\

SD_{intransitive} &= \frac{SE_{Raw}}{Time_{correct} + Time_{incorrect}} * \sqrt[2]{N} \\
  &= \frac{0.4}{3.33 + 4.12} *  \sqrt[2]{8} \\
  &= 0.152 \\
\\
\\
\end{aligned}

Using the standardized data as presented in the table below, we calculate Cohen's d and the variances as follows (the implementation of the script can be found at XXX)

```{r}
tibble(
  "Dialogue Type" = c("Transitive", "Intransitive"),
    "Sample Size" = c("8", "8"),
  #"Mean Proportion Calculation" = c("4.82 / (4.82 + 2.87)", "4.12 / (3.33 + 4.12)"), 
  "Mean Proportion" = c("0.627", "0.553"), 
  #"Standard Deviation Calculation" = c("(0.43 / (4.82 + 2.87)) * (8^0.5)", "(0.4 / (3.33 + 4.12)) * (8^0.5)"),
  "Standard Deviation" = c("0.158", "0.152")) %>% kable() %>% 
  kable_styling(font_size = 12)
```




\begin{aligned}
 d_{transitive} &= \frac{M_1 - M_2}{\sigma_{pooled}} \\
  &= \frac{M_{correct} - M_{chance}}{\sigma_{correct}} \\
  &= \frac{0.627 - 0.5}{0.158} \\
  &\approx 0.79 \\
  \\
  \\
  d_{intransitive} &= \frac{M_1 - M_2}{\sigma_{pooled}} \\
  &= \frac{M_{correct} - M_{chance}}{\sigma_{correct}} \\
  &= \frac{0.553 - 0.5}{0.152} \\
  &\approx 0.35
  
\end{aligned}


\begin{aligned}
var(d_{transitive}) &= \frac{1}{N} + \frac{d^2}{2 * N} \\
&= \frac{1}{8} + \frac{0.79^2}{2 * 8} \\
&\approx 0.16 \\

var(d_{intransitive}) &= \frac{1}{N} + \frac{d^2}{2 * N} \\
&= \frac{1}{8} + \frac{0.35^2}{2 * 8} \\
&\approx 0.13 \\
\end{aligned}




# Sensitivity analysis

```{r}
ma_data_with_affirm <- ma_data %>%
  mutate(pvalue =  2 * (1 - pnorm( abs(d_calc / sqrt(d_var_calc)))),
         affirm =  (d_calc > 0) & (pvalue < 0.05))

affirm_model<- rma.mv(d_calc,  d_var_calc,  
                         random = ~ 1 | short_cite/same_infant/row_id, data=
          ma_data_with_affirm %>% filter(affirm == FALSE)) 

affirm_estimate <- as.numeric(affirm_model$b)

worst_case_estimate_print <- paste0(as.numeric(round(affirm_model$beta, 2)),
                                    " [",
                                    as.numeric(round(affirm_model$ci.lb, 2)),
                                    ", ",                                                                                                        as.numeric(round(affirm_model$ci.ub, 2)),
                                    "]")
 
all_model <- rma.mv(d_calc,  d_var_calc,  
                         random = ~ 1 | short_cite/same_infant/row_id, data=
          ma_data_with_affirm)
all_estimate <- as.numeric(all_model$ b)

```

The plot below shows a modified funnel plot, or "significance funnel" where significant studies are shown in orange and non-significant studies are shown in grey (Marthur & VanderWeele, 2020). The x-axis shows effect size estimates, and the y-axis shows estimated standard error for each estimate. Studies lying on the grey line have a p-value of .05. The black diamond shows the meta-analytic effect size estimate for all studies; the grey diamond shows the meta-analytic effect size estimate for significant studies only (the "worst-case" publication scenario). Note that the worst case scenario appreciable attenuates the effect size estimate, but does not attenuate the point estimate to 0 (worst case estimate: `r worst_case_estimate_print`).



```{r}

significance_funnel <- function (yi, vi, xmin = min(yi), xmax = max(yi), ymin = 0, ymax = max(sqrt(vi)), 
    xlab = "Point estimate", ylab = "Estimated standard error", 
    favor.positive = NA, est.all = NA, est.N = NA, alpha.select = 0.05, 
    plot.pooled = TRUE) 
{
    d = data.frame(yi, vi)
    d$sei = sqrt(vi)
    d$pval = 2 * (1 - pnorm(abs(yi)/sqrt(vi)))
    if (!is.na(est.all) & is.na(favor.positive)) {
        favor.positive = (est.all > 0)
        warning("favor.positive not provided, so assuming publication bias favors estimates whose sign matches est.all")
    }
    if (is.na(est.all) & is.na(favor.positive)) {
        stop("Need to specify favor.positive")
    }
    d$affirm = rep(NA, nrow(d))
    if (favor.positive == TRUE) {
        d$affirm[(d$yi > 0) & (d$pval < alpha.select)] = "Affirmative"
        d$affirm[(d$yi < 0) | (d$pval >= alpha.select)] = "Non-affirmative"
    }
    if (favor.positive == FALSE) {
        d$affirm[(d$yi < 0) & (d$pval < alpha.select)] = "Affirmative"
        d$affirm[(d$yi > 0) | (d$pval >= alpha.select)] = "Non-affirmative"
    }
    d$affirm = factor(d$affirm, c("Non-affirmative", "Affirmative"))
    if (sum(d$affirm == "Non-affirmative") == 0) {
        stop("There are no non-affirmative studies. The plot would look silly.")
    }
    if (sum(d$affirm == "Affirmative") == 0) {
        stop("There are no affirmative studies. The plot would look silly.")
    }
    if (is.na(est.N) & is.na(est.all)) {
        est.N = rma.uni(yi = d$yi[d$affirm == "Non-affirmative"], 
            vi = d$vi[d$affirm == "Non-affirmative"], method = "FE")$b
        est.all = rma.uni(yi = d$yi, vi = d$vi, method = "FE")$b
    }
    pooled.pts = data.frame(yi = c(est.N, est.all), sei = c(0, 
        0))
    just_signif_est = function(.sei) .sei * qnorm(1 - alpha.select/2)
    if (favor.positive == TRUE) 
        sl = 1/qnorm(1 - alpha.select/2)
    if (favor.positive == FALSE) 
        sl = -1/qnorm(1 - alpha.select/2)
    int = 0
    colors = c("darkgray", "orange")
    p.funnel = ggplot(data = d, aes(x = d$yi, y = d$sei, color = d$affirm))
    if (plot.pooled == TRUE) {
        p.funnel = p.funnel + geom_point(data = pooled.pts, aes(x = pooled.pts$yi, 
            y = pooled.pts$sei), size = 4, shape = 5, fill = NA, 
            color = c(colors[1], "black")) + geom_point(data = pooled.pts, 
            aes(x = pooled.pts$yi, y = pooled.pts$sei), size = 4, 
            shape = 18, color = c(colors[1], "black"), alpha = 1) + 
            geom_hline(yintercept = 0) + geom_abline(slope = sl, 
            intercept = int, color = "gray")
    }
    p.funnel = p.funnel + geom_point(size = 3, alpha = 0.3) + 
        geom_point(size = 3, shape = 1) + scale_color_manual(values = colors) + 
        xlab(xlab) + ylab(ylab) + scale_x_continuous(limits = c(xmin, 
        xmax)) + scale_y_continuous(limits = c(ymin, ymax)) + 
        theme_classic() + theme(legend.title = element_blank())
    plot(p.funnel)
}


significance_funnel(
  ma_data$d_calc,
  ma_data$d_var_calc,
  xmin = min(ma_data$d_calc),
  xmax = max(ma_data$d_calc),
  ymin = 0,
  ymax = max(sqrt(ma_data$d_var_calc)),
  xlab = "Estimate Effect Size (Cohen's d)",
  ylab = "Estimated standard error",
  favor.positive = TRUE,
  est.all = all_estimate,
  est.N = affirm_estimate,
  alpha.select = 0.05,
  plot.pooled = TRUE
)

```


# Main model results  {.tabset}

The tables below show the estimates for the single-moderator models reported in the main text. Across all the single-predictor model, the predicate type is significant, such that hearing transitive sentences have a positive effect on the effect size. We also found that median vocabulary size is a marginally significant moderator. 

In the tables throughout the supplemental information, we reported the point estimates for the parameters and their 95% confidence intervals in square brackets (i.e., [lower bound, upper bound].) For estimates that reaches a p-value of 0.05, we put an asterisk (*) near the number. For categorical variables, the base levels are represented as the first ones appeared in the parentheses. 
```{r}
MODERATORS <- c( "NULL", "mean_age_months","productive_vocab_median", "sentence_structure", "agent_argument_type", "patient_argument_type", "n_repetitions_sentence",  "stimuli_modality", "stimuli_actor", "transitive_event_type","intransitive_event_type", "presentation_type","character_identification", "practice_phase", "test_mass_or_distributed", "n_train_test_pair", "n_test_trial_per_pair" )



si_mod_print <- generate_moderator_df(MODERATORS, ma_data) 

```

## Mean age 
```{r}
convert_pretty_print_table(si_mod_print, "mean_age_months") %>%
  mutate(Parameter = case_when(
    Parameter == "Mean Age Months" ~ "Mean Age (months)",
    TRUE ~ Parameter
  )) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Median productive vocabulary size
```{r}
convert_pretty_print_table(si_mod_print, "productive_vocab_median") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Productive Vocab Median" ~ "Median productive vocabulary size", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Predicate Type
```{r}
convert_pretty_print_table(si_mod_print, "sentence_structure") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Sentence Structure" ~ "Predicate type (Transitive / Intransitive)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Noun phrase type
```{r}
convert_pretty_print_table(si_mod_print, "agent_argument_type") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Agent Argument Type" ~ "Noun phrase type (Pronoun / Noun)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Character identification phase
```{r}
convert_pretty_print_table(si_mod_print, "character_identification") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Character Identification" ~ "Character identification phase \n (Yes / No)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Practice phase 
```{r}
convert_pretty_print_table(si_mod_print, "practice_phase") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Practice Phase" ~ "Practice phase \n (Yes / No)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Synchronicity 
```{r}
convert_pretty_print_table(si_mod_print, "presentation_type") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Presentation Type" ~ "Synchronicity \n (Simultaneous / Asynchronous)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Testing structure 
```{r}
convert_pretty_print_table(si_mod_print, "test_mass_or_distributed") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Test Mass Or Distributed" ~ "Testing Procedure Structure \n (Mass / Distributed)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Number of sentence repetitions
```{r}
convert_pretty_print_table(si_mod_print, "n_repetitions_sentence") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "N Repetitions Sentence" ~ "Number of sentence repetitions", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

# Main models results using dataset without imputed values {.tabset}
As mentioned in the method sections, for studies missing relevant statistics, we imputed values from studies with similar design (e.g. Hirsh-Pasek, Golinkoff,& Naigles, 1996). The tables below report the model results from fitting the exact same models on the dataset excluding the imputed study. There was no significant difference between the outcomes from the two datasets. 

```{r}
MODERATORS <- c( "NULL", "mean_age_months","productive_vocab_median", "sentence_structure", "agent_argument_type", "patient_argument_type", "n_repetitions_sentence",  "stimuli_modality", "stimuli_actor", "transitive_event_type","intransitive_event_type", "presentation_type","character_identification", "practice_phase", "test_mass_or_distributed", "n_train_test_pair", "n_test_trial_per_pair" )

si_mod_print_no_impute <- generate_moderator_df(MODERATORS,filter(ma_data,  data_source != "imputed"))

```

## Mean age
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "mean_age_months") %>% 
  mutate(Parameter = case_when(
    Parameter == "Mean Age Months" ~ "Mean Age (months)",
    TRUE ~ Parameter
  )) %>% 
  kable() %>% 
  kable_styling(font_size = 12)

```

## Median productive vocabulary size
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "productive_vocab_median") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Productive Vocab Median" ~ "Median productive vocabulary size", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Predicate Type
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "sentence_structure") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Sentence Structure" ~ "Predicate type (Transitive / Intransitive)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Noun phrase type
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "agent_argument_type") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Agent Argument Type" ~ "Noun phrase type (Pronoun / Noun)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Character identification phase
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "character_identification") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Character Identification" ~ "Character identification phase \n (Yes / No)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Practice phase 
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "practice_phase") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Practice Phase" ~ "Practice phase \n (Yes / No)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Synchronicity 
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "presentation_type") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Presentation Type" ~ "Synchronicity \n (Simultaneous / Asynchronous)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Testing structure 
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "test_mass_or_distributed") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "Test Mass Or Distributed" ~ "Testing Procedure Structure \n (Mass / Distributed)", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

## Number of sentence repetitions
```{r}
convert_pretty_print_table(si_mod_print_no_impute, "n_repetitions_sentence") %>% 
  mutate(
    Parameter = case_when(
    Parameter == "N Repetitions Sentence" ~ "Number of sentence repetitions", 
    TRUE ~ Parameter)
  ) %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

# Models with Methodological Moderators and Theoretical Moderators {.tabset}
Syntactic Bootstrapping studies differ in their implementational details. Here we examine to what extent the influences of the theoretical moderators can be accounted for by the methodological factors. The tables below present the results of models that include all the key methodological moderators and one of the theoretical moderators. The patterns were consistent with the single-predictor theoretical models: predicate type is still a significant predictor of the effect. 

In the tables below we highlight the rows representing theoretical moderators in yellow.

## With age
```{r}
age_method_m <- fit_method_model("mean_age_months", ma_data)
age_print_table <- print_method_model(age_method_m) %>% 
  mutate(Parameter = case_when(
    Parameter == "Mean Age Months" ~ "Mean Age (months)", 
    TRUE ~ Parameter
  ))
age_print_table %>% 
  kable() %>% 
  kable_styling(font_size = 12) %>% 
  row_spec(which(age_print_table$Parameter == "Mean age (months)"),bold = T, color = "black", background = "wheat")


```

## With productive vocabulary size 
```{r}
vocab_method_m <- fit_method_model("productive_vocab_median", ma_data)
vocab_print_table <- print_method_model(vocab_method_m) 
vocab_print_table %>% 
  kable() %>% 
  kable_styling(font_size = 12) %>% 
  row_spec(which(vocab_print_table$Parameter == "Median productive vocabulary size"),bold = T,  color = "black", background = "wheat")

```

## With predicate type
```{r}
sentence_structure_method_m <- fit_method_model("sentence_structure", ma_data)
sentence_structure_print_table <- print_method_model(sentence_structure_method_m)
sentence_structure_print_table %>% 
  kable() %>% 
  kable_styling(font_size = 12) %>% 
  row_spec(which(sentence_structure_print_table$Parameter == "Predicate type (Intransitive / Transitive)"),bold = T, color = "black", background = "wheat")

```

## With Noun phrase type
```{r}
argument_type_method_m <- fit_method_model("agent_argument_type", ma_data)
argument_type_print <- print_method_model(argument_type_method_m) 

argument_type_print%>% 
  kable() %>% 
  kable_styling(font_size = 12) %>% 
  row_spec(which(argument_type_print$Parameter == "Noun phrase type (Noun / Pronoun)"),bold = T, color = "black", background = "wheat")
```




# Additional Moderators 
## Relationship between moderators {.tabset}

We coded additional moderators, including the modality of, the actors in and the event types in the visual stimuli. Stimuli modality has two levels: videos and animations. We coded this moderator following the details provided in the method sections of the papers. Stimuli actors have two levels, human actors and non-human actors. Studies using visual stimuli with human actors wearing animal suits were coded as using non-human actors. To capture the event types of the visual stimuli, we coded the transitive action stimuli and the intransitive action stimuli separately. The transitive event has two levels: direct caused action and indirect caused action. The event was coded as using direct caused action if the agent in the action directly acted upon the patient. It was coded as using indirect caused action if the agent caused the patient to move via another medium. For example, the agent may pull a band on the patient's waist causing her to move. Likewise, the intransitive event also has two levels: one action versus parallel actions. Here we coded the levels by number of participants presented on the screen. An intransitive event was coded as "one action" if and only if there was only one agent presented on the screen. If an event involves more than one actor in the intransitive event (e.g. two actors doing parallel actions or one actor with one stander-by), then the event was coded as parallel-actions.

These additional moderators were not included in the main analyses because of their close relationships between each other and with the main moderators. The heatmaps below showed the overlappings between moderators. Each cell corresponds to the co-occurrence between two moderator levels. Brighter colors indicate a higher frequency of co-occurrence, and darker colors indicate lower frequency. You can hover your mouse on the heatmap to see the corresponding value and combination of each cell. 


### Ordered by Row Average 
```{r fig.width=9.5, fig.height=9.5}
ALL_CATEGORICAL_VARS <- c("presentation_type",
                      #"agent_argument_type", "patient_argument_type", 
                     "stimuli_modality", "stimuli_actor", "character_identification",   "practice_phase", "test_mass_or_distributed", "transitive_event_type", "intransitive_event_type")


get_cross_counts <- function(args, df){
  var1 = args[[1]]
  var2 = args[[2]]
  
  if (var1 != var2){
  
  df %>%
    select_(var1, var2) %>%
    rename(v1 = var1, 
          v2 = var2) %>%
    count(v1, v2) %>%
    mutate(v1_long = glue("{var1}/{v1}"),
           v2_long = glue("{var2}/{v2}"))  %>%
    select(v1_long, v2_long, n) 

  }
}

all_pair_counts <- list(ALL_CATEGORICAL_VARS,
                        ALL_CATEGORICAL_VARS) %>%
  cross() %>%
  map_df(get_cross_counts, ma_data) %>%
  complete(v1_long, v2_long, fill = list(n = 0)) %>%
  filter(v1_long != v2_long)


  all_counts_wide <- all_pair_counts %>%
    pivot_wider(names_from = v2_long, values_from = n) 
  

  all_counts_wide_matrix <- all_counts_wide %>%
    select(-v1_long) %>%
    as.matrix()
  
  row.names(all_counts_wide_matrix) <-  as.character(all_counts_wide$v1_long)
  heatmaply(all_counts_wide_matrix,
            fontsize_row = 8,
            fontsize_col = 8)
```

### Ordered by groups        
```{r fig.width=9.5, fig.height=9.5}
ALL_VARS <- colnames(all_counts_wide_matrix)
ALL_VARS <- c("character_identification/yes", 
              "character_identification/no", 
              "practice_phase/yes", 
              "practice_phase/no", 
              "transitive_event_type/direct_caused_action",
              "transitive_event_type/indirect_caused_action", 
              "intransitive_event_type/one_action", 
              "intransitive_event_type/parallel_actions" , 
              "presentation_type/asynchronous", 
              "presentation_type/simultaneous", 
              "test_mass_or_distributed/mass", 
              "test_mass_or_distributed/distributed", 
              "stimuli_actor/person", 
              "stimuli_actor/non_person", 
              "stimuli_modality/video", 
              "stimuli_modality/animation"
              )

ordered_matrix <- all_counts_wide_matrix %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  slice(match(ALL_VARS, rowname)) %>% 
  column_to_rownames("rowname") %>% 
  select(all_of(ALL_VARS))

heatmaply(ordered_matrix,
            fontsize_row = 8,
            fontsize_col = 8,
           Rowv = NA, 
          Colv = NA)
```



## Model results {.tabset}
The tables here present some exploratory moderators. The base levels for the categorical moderators are the first ones in the parentheses. 
```{r include=FALSE}
ADDITIONAL_MODERATORS <- c("stimuli_modality", "stimuli_actor",  "transitive_event_type", "intransitive_event_type")
INTRANSITIVE <- c("patient_argument_type")
additional_main <- generate_moderator_df(ADDITIONAL_MODERATORS, ma_data)
intransitive <- generate_moderator_df(INTRANSITIVE, filter(ma_data, sentence_structure == "transitive"))
additional_main <- bind_rows(additional_main, intransitive) %>% 
  select(this_moderator, n, 
         estimate_print_full, z_print, p_print, p, moderator_p,
         mod_estimate_print_full, mod_CI_print, mod_z_print, mod_p_print) %>% 
  mutate(
    intercept = estimate_print_full, 
    moderator = mod_estimate_print_full,
    intercept_z_val = gsub("= ","", z_print), 
    intercept_p_val = gsub("= ", "", p_print),
    mod_z_val = gsub("= ", "", mod_z_print),
    mod_p_val = gsub("= ", "", mod_p_print)
  )

```

### Patient argument type for transitive sentence 

In the main analysis, we presented the results of the model for the relationship between effect size and the agent argument type. We found that having nouns or pronouns int he agent argument does not significantly predict the effect size. Here, we presented a similar analysis of the influence of the patient argument type. Because by definition English intransitive sentences do not have patient argument, we focus on the subset of studies that used the transitive sentences ($N$ = `r filter(additional_main, this_moderator == "patient_argument_type")$n`)

```{r}
patient_argument_type_table <- convert_pretty_print_table(additional_main, "patient_argument_type") %>% 
  mutate(
    Parameter = case_when(
      Parameter == "Patient Argument Type" ~ "Patient Argument Type (Noun / Pronoun)",
      TRUE ~ Parameter
    )
  )

patient_argument_type_table %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```



### Stimuli Modality

We found that the presentation modality of the stimuli was not a significant predictor of the effect size. In other words, studies that presented young children with animation clips had similar effect sizes as studies using video clips. The model statistics are shown below. Note that the stimuli modality and the stimuli actor levels had a lot of overlapping studies, so researchers should interpret this result with caution. 


```{r}
stimuli_argument_type_table <- convert_pretty_print_table(additional_main, "stimuli_modality") %>% 
  mutate(
    Parameter = case_when(
      Parameter == "Stimuli Modality" ~ "Stimuli Modality (Animation / Video)",
      TRUE ~ Parameter
    )
  )
stimuli_argument_type_table %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```


### Stimuli actors
There is a marginal effect of stimuli actor. Studies with human actors as protagonists in the events had relatively smaller effect sizes as studies using puppets, human actors in animal suits, or using animated geometrical shapes. This might due to the relatively higher visual complexity associated with stimuli using real human actors.  

```{r}
stimuli_actor_type_table <- convert_pretty_print_table(additional_main, "stimuli_actor")  %>% 
  mutate(
    Parameter = case_when(
      Parameter == "Stimuli Actor" ~ "Stimuli Actor (Non-person / Person)",
      TRUE ~ Parameter
    )
  )
stimuli_actor_type_table %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```

### Type of event {.tabset}
Studies differed in the type of transitive events and intransitive events they presented. Previous studies have shown that young children's looking behaviors in Inter-modal Preferential Looking Paradigm were very sensitive to the subtle perceptual differences in the visual stimuli (Delle Luche, Durrant, Poltrock, & Floccia, 2015; Fernald, Zangl, Portillo, & Marchman, 2008). Therefore, we coded the types of events presented in the visual stimuli. There were two types of transitive events: direct causal action and indirect causal action. The former involved the agent directly acting on the patient and causing the patient to move. The latter involved a mean-end sequence leading to the caused action of the patient. For example, the agent may pull a band on the patient's waist and caused it to move. There were also two types of intransitive events used in the literature. One involved a single actor acting, such as jumping up and down. The other involved two actors presented without any causal action. 

Our model suggested that neither of the variables was predictive of the effect sizes. 



#### Transitive Event type
```{r}
transitive_event_type_table <- convert_pretty_print_table(additional_main, "transitive_event_type")  %>% 
  mutate(
    Parameter = case_when(
      Parameter == "Transitive Event Type" ~ "Transitive Event Type (Direct caused action / Indirect caused action)",
      TRUE ~ Parameter
    )
  )


transitive_event_type_table %>% 
  kable()%>% 
  kable_styling(font_size = 12)
```
#### Intransitive event type
```{r}
intransitive_event_type_table <- convert_pretty_print_table(additional_main, "intransitive_event_type")  %>% 
  mutate(
    Parameter = case_when(
      Parameter == "Intransitive Event Type" ~ "Intransitive Event Type (One action / Parallel actions)",
      TRUE ~ Parameter
    )
  )

intransitive_event_type_table %>% 
  kable() %>% 
  kable_styling(font_size = 12)
```




# Variability in visual stimuli as a function of age

There was some evidence for researchers adapting the level of visual complexity in the visual stimuli according to children's age. We collected the available visual stimuli from the papers and the supporting materials. Schematic illustrations of the visual stimuli were used when the actual screenshots were not provided. Screenshots of the text descriptions of the events were used when the visual stimuli were unavailable. Note that because some papers' publishers converted to the visual stimuli to black-and-white, we decided to grayscale all visual stimuli for easier visual comparison.  

It is easy to see in the plot that studies for particularly young children used significantly simpler visual stimuli. This adaptation might be partly responsible for the lack of age effect observed in our samples.  


```{r}

ma_data <- read_csv(DATA_PATH) %>% 
  mutate(row_id = 1:n()) %>%
  rowwise() %>%
  mutate(stim_path = paste(unique_id, expt_num, sentence_structure,sep = "_"),
         stim_path = paste0(here("resources/stimuli_forplot/"), stim_path, ".png"),
         stim_path = str_replace(stim_path, "yuan2012_3_", "yuan2012_3simple_"))


age_model <- rma.mv(d_calc ~ mean_age, V = d_var_calc,
                      random = ~ 1 | short_cite/same_infant/row_id,
                      method = "REML",
                      data = ma_data )


```

```{r, fig.width = 10, fig.height = 8}
ma_data_with_predictions <- predict(age_model) %>%
  as.data.frame() %>%
  bind_cols(ma_data) %>% 
  mutate(
    mean_age_months = mean_age / 30.44
  )

ggplot(ma_data_with_predictions, aes(x = mean_age_months, y = d_calc)) +
  geom_image(aes(image = stim_path)) +
  geom_smooth(method = "lm") +
  #geom_smooth(method = "lm", data = ma_data_with_predictions, aes(x = mean_age, y = pred)) +
  scale_x_continuous(breaks = seq(0, 48, by = 12), limits = c(9, 48)) +
  geom_hline(aes(yintercept = 0), color = "black", linetype = "dashed") +
  ylab("Effect Size (d)") +
  xlab("Mean age (months)")
```





# Power analysis 
```{r}

pwr_no_mod_model <- rma.mv(d_calc~1, 
                            V  = d_var_calc,
                            random = ~ 1 |short_cite/same_infant/row_id, 
                            
                  data = ma_data, method = "REML")


mean_sample_size <- mean(ma_data$n_1)

d_pwr <- pwr_no_mod_model$b[,1][["intrcpt"]]
pwr_80 <- pwr::pwr.p.test(
  h = d_pwr, 
  sig.level = .05, 
  power = .8)$n
current_power <- pwr::pwr.p.test(h = d_pwr, 
           n = mean_sample_size, 
           sig.level = .05
           )$power


```

We conducted a power analysis using the `pwr` package. The x-axis represents the number of participants in each condition, and the y-axis represents the estimated power based on the power of current estimated meta-analytic effect size. The horizontal black dotted line represents 80% power, and the vertical black dotted lines represent the number of participants needed to reach 80% power (*N* = `r round(pwr_80, 0)`). The red lines represents the current power (`r round(current_power * 100, 2)`%) based on the approximate mean sample sizes (*N* = `r round(mean_sample_size, 0)`) of the conditions included in the meta-analysis.
```{r}
max_n <- min(max(60,
                     pwr::pwr.p.test(h = d_pwr,
                                     sig.level = .05,
                                     power = .9)$n),
                 200)

pwrs <- data.frame(ns = seq(5, max_n, 5),
                   ps = pwr::pwr.p.test(h = d_pwr,
                                        n = seq(5, max_n, 5),
                   sig.level = .05)$power,
                   stringsAsFactors = FALSE)

qplot(ns, ps, geom = c("point","line"),
          data = pwrs) +
      geom_hline(yintercept = .8, lty = 2) +
      geom_vline(xintercept = pwr_80, lty = 3) +
      geom_hline(yintercept = current_power, lty = 2, color = "red") +
      geom_vline(xintercept = mean_sample_size, lty = 3, color = "red")+
      ylim(c(0,1)) +
      xlim(c(0,max_n)) +
      ylab("Power to reject the null at p < .05") +
      xlab("Number of participants (N)")
```





**References**


Delle Luche, C., Durrant, S., Poltrock, S., & Floccia, C. (2015). A methodological investigation of the Intermodal Preferential Looking paradigm: Methods of analyses, picture selection and data rejection criteria. Infant Behavior and Development, 40, 151-172

Fernald, A., Zangl, R., Portillo, A. L., & Marchman, V. A. (2008). Looking while listening: Using eye movements to monitor spoken language. Developmental psycholinguistics: On-line methods in children’s language processing, 44, 97.

Mathur, M. B., & VanderWeele, T. J. (2020). Sensitivity analysis for publication bias in meta‐analyses. Journal of the Royal Statistical Society. Series C, Applied Statistics, 69(5), 1091.


